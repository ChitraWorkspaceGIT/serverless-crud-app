### Serverless CRUD App

A simple serverless CRUD (Create, Read, Update, Delete) application built on AWS using S3, Lambda, API Gateway, and DynamoDB.

This project demonstrates how to:

Upload data files to S3 â†’ automatically store in DynamoDB via Lambda.

Manage items via a REST API built with API Gateway + Lambda.

Perform CRUD operations (GET, POST, DELETE) without managing servers.

ðŸš€ Architecture

1. Amazon S3

Stores uploaded JSON files.

Triggers a Lambda when a file is uploaded.

AWS Lambda

Processes S3 file uploads and saves data into DynamoDB.

Provides business logic for API requests (GET, POST, DELETE).

Amazon DynamoDB

NoSQL database to store items.

Amazon API Gateway

Exposes REST API endpoints:

GET /items â†’ list all items

POST /items â†’ add an item

DELETE /items/{id} â†’ delete item by IDðŸŸ¢ Step 1: Create an S3 Bucket

ðŸ”§ Technologies Used

AWS Lambda (Python 3.9 runtime)

Amazon S3 (storage + event trigger)

Amazon DynamoDB (NoSQL database)

Amazon API Gateway (REST API)

IAM Roles & Policies (permissions)

CloudWatch Logs (monitoring & error logging)

Open the AWS Console â†’ Go to S3.

Click Create bucket.

Enter a unique name (example: my-serverless-items-bucket).

Choose a region (e.g., ap-south-1).

Leave all other options default â†’ Create.

ðŸ‘‰ Why?
This bucket is like a folder on the cloud where you can upload JSON files.

Example file:

{
  "id": "1",
  "name": "Book",
  "category": "Stationery"
}

ðŸŸ¢ Step 2: Create a DynamoDB Table

Open DynamoDB in AWS Console.

Go to Tables â†’ Create table.

Table name: ItemsTable.

Partition key: id (String).

Leave defaults â†’ Create table.

ðŸ‘‰ Why?
DynamoDB is where all your items will be stored like a database.

ðŸŸ¢ Step 3: Create an IAM Role for Lambda

Open IAM â†’ Roles â†’ Create Role.

Trusted entity: Lambda.

Attach permissions:

AmazonS3FullAccess

AmazonDynamoDBFullAccess

CloudWatchLogsFullAccess

Name it: lambda-s3-dynamo-role.

ðŸ‘‰ Why?
This role gives permission for Lambda functions to read from S3, write to DynamoDB, and log errors to CloudWatch.

ðŸŸ¢ Step 4: Create Lambda Function (S3 â†’ DynamoDB)

Go to Lambda â†’ Create Function.

Function name: s3-to-dynamodb-func.

Runtime: Python 3.9.

Choose the IAM role lambda-s3-dynamo-role.

Paste this code:

import json
import boto3

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('ItemsTable')

def lambda_handler(event, context):
    s3 = boto3.client('s3')

    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']

        response = s3.get_object(Bucket=bucket, Key=key)
        content = response['Body'].read().decode('utf-8')
        data = json.loads(content)

        table.put_item(Item={
            'id': data['id'],
            'name': data['name'],
            'category': data.get('category', 'unknown')
        })

    return {"statusCode": 200, "body": "Saved to DynamoDB"}


ðŸ‘‰ Why?
This Lambda is triggered when a file is uploaded to S3. It reads the file and saves the data into DynamoDB.

ðŸŸ¢ Step 5: Connect S3 to Lambda

Open your Lambda â†’ Add Trigger.

Choose S3.

Select your bucket (my-serverless-items-bucket).

Event type: PUT (when a new file is created).

Save.

ðŸ‘‰ Now: Every time you upload a JSON file â†’ it will be stored in DynamoDB automatically.

ðŸŸ¢ Step 6: Test the Flow

Upload item1.json into S3:

{
  "id": "1",
  "name": "Book",
  "category": "Stationery"
}


Go to DynamoDB â†’ Explore Table.

âœ… Youâ€™ll see the item saved (id=1, name=Book).

ðŸŸ¢ Step 7: Create Another Lambda (for API CRUD)

Go to Lambda â†’ Create Function.

Function name: items-api-func.

Runtime: Python 3.9.

Attach the same role (lambda-s3-dynamo-role).

Paste this code:

import json
import boto3

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('ItemsTable')

def lambda_handler(event, context):
    method = event['requestContext']['http']['method']

    if method == "GET":
        items = table.scan()
        return {"statusCode": 200, "body": json.dumps(items['Items'])}

    elif method == "POST":
        body = json.loads(event['body'])
        table.put_item(Item=body)
        return {"statusCode": 200, "body": "Item added"}

    elif method == "DELETE":
        item_id = event['pathParameters']['id']
        table.delete_item(Key={'id': item_id})
        return {"statusCode": 200, "body": "Item deleted"}

    return {"statusCode": 400, "body": "Unsupported method"}


ðŸ‘‰ Why?
This Lambda handles API requests to view, add, or delete items.

ðŸŸ¢ Step 8: Set Up API Gateway

Go to API Gateway â†’ Create API â†’ HTTP API.

Name: items-api.

Integrate it with items-api-func.

Add routes:

GET /items â†’ items-api-func

POST /items â†’ items-api-func

DELETE /items/{id} â†’ items-api-func

Deploy â†’ Stage name: prod.

ðŸ‘‰ After deployment, you get an Invoke URL like:

https://abc123.execute-api.ap-south-1.amazonaws.com/prod

ðŸŸ¢ Step 9: Test the API

GET all items

GET https://abc123.execute-api.ap-south-1.amazonaws.com/prod/items


POST add new item

POST https://abc123.execute-api.ap-south-1.amazonaws.com/prod/items
Body:
{
  "id": "2",
  "name": "Laptop",
  "category": "Electronics"
}


DELETE an item

DELETE https://abc123.execute-api.ap-south-1.amazonaws.com/prod/2


âœ… Now you have a fully working serverless CRUD app!

ðŸŽ¯ What You Achieved

Learned how S3 can trigger Lambda.

Used DynamoDB as a serverless database.

Created REST APIs with API Gateway + Lambda.

Tested end-to-end CRUD operations without any servers.

Logging & error tracking available in CloudWatch.
